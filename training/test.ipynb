{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.7 64-bit",
   "display_name": "Python 3.7.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "a4ca0a1be38340d2e1b70bc6cc73081324f38c92d6b10994d2eeb96728463324"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "14it [00:04,  3.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# chunk your dataframes in small portions\n",
    "chunks = pd.read_csv(\"comments_trustpilot_v2.csv\",\n",
    "                         usecols=['comment', 'rating'],\n",
    "                         chunksize=50000)\n",
    "texts = []\n",
    "labels = []\n",
    "for df_chunk in tqdm(chunks):\n",
    "    aux_df = df_chunk.copy()\n",
    "    aux_df = aux_df.sample(frac=1)\n",
    "    aux_df = aux_df[~aux_df['comment'].isnull()]\n",
    "    aux_df = aux_df[(aux_df['comment'].map(len) > 1)]\n",
    "    aux_df['processed_text'] = (aux_df['comment'].map(lambda text: utils.process_text(['lower'], text)))\n",
    "    texts += aux_df['processed_text'].tolist()\n",
    "    labels += aux_df['rating'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=list(map(lambda l: {1: 0, 2: 0,3:1,4: 2, 5: 2}[l], labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label balance\n",
    "counter = Counter(labels)\n",
    "keys = list(counter.keys())\n",
    "values = list(counter.values())\n",
    "count_minority = np.min(values)\n",
    "\n",
    "balanced_labels = []\n",
    "balanced_texts = []\n",
    "\n",
    "for key in keys: \n",
    "    balanced_texts += [text for text, label in zip(texts, labels) if label == key][:int(count_minority)]\n",
    "    balanced_labels += [label for text, label in zip(texts, labels) if label == key][:int(count_minority)] \n",
    "\n",
    "texts = balanced_texts\n",
    "labels = balanced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({2: 24563, 0: 24563, 1: 24563})"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(labels)\n",
    "counter = dict(counter)\n",
    "for k in counter:\n",
    "    counter[k] = 1 / counter[k]\n",
    "sample_weights = np.array([counter[l] for l in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "73689"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "len(sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([4.07116395e-05, 4.07116395e-05, 4.07116395e-05, ...,\n",
       "       4.07116395e-05, 4.07116395e-05, 4.07116395e-05])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(list(set(labels)))\n",
    "class_names = [str(class_name) for class_name in class_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['0', '1', '2']"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary=\"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+ =<>()[]{}\"\n",
    "number_of_characters=69\n",
    "max_length=150\n",
    "identity_mat=np.identity(number_of_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = texts[0]\n",
    "data = np.array([identity_mat[vocabulary.index(i)] for i in list(raw_text)[::-1] if i in vocabulary],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['.', 'm', 'e', 'h', 't', ' ', 'f', 'o', ' ', 'y', 'n', 'a', ' ',\n",
       "       'e', 's', 'o', 'l', ' ', 't', 'â€™', 'n', 'o', 'd', ' ', 'i', ' ',\n",
       "       'e', 'p', 'o', 'h', ' ', 'i', ' ', 'd', 'n', 'a', ' ', 'r', 'e',\n",
       "       'v', 'e', 'w', 'o', 'h', ' ', 'p', 'i', 'r', 't', ' ', 'r', 'i',\n",
       "       'e', 'h', 't', ' ', 'm', 'o', 'r', 'f', ' ', 'd', 'e', 's', 's',\n",
       "       'e', 'r', 't', 's', ' ', 'y', 'r', 'e', 'v', ' ', 'e', 'r', 'e',\n",
       "       'w', ' ', 'y', 'e', 'h', 't', ' ', '.', 'h', 's', 'i', 'f', ' ',\n",
       "       's', 'u', 'c', 's', 'i', 'd', ' ', 'w', 'e', 'n', ' ', 'y', 'm',\n",
       "       ' ', 'e', 'v', 'o', 'l', ' ', 'r', 'e', 'd', 'r', 'o', ' ', 'y',\n",
       "       'm', ' ', 'h', 't', 'i', 'w', ' ', 'y', 'p', 'p', 'a', 'h', ' ',\n",
       "       'y', 'l', 'l', 'a', 'e', 'r'], dtype='<U1')"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "np.array([i for i in list(raw_text)[::-1] if i not in vocabulary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "identity_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}